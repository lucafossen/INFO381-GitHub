{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Comment out if not using colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Specific for luca's computer\n",
    "    %cd \"/content/drive/Othercomputers/Min MacBook Pro/INFO381-GitHub\"\n",
    "    using_colab = True\n",
    "except:\n",
    "    print(\"Not using Google Colab\")\n",
    "    using_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ot/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/ot/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = \"cifar_train_test/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ImageFolder(root = path_test, transform = transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ot/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ot/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained = False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "model.load_state_dict(torch.load(\"resnet18_cnn.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set to evaluation mode\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)  # Get the predicted class\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 600x600 with 1 Axes>,\n",
       " <AxesSubplot:title={'center':'Grad-CAM Heatmap'}>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from captum.attr import LayerGradCam, visualization\n",
    "\n",
    "# Move inputs to device\n",
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "# Define Grad-CAM explainer\n",
    "grad_cam = LayerGradCam(model, model.layer4[-1])  # Try last conv layer\n",
    "\n",
    "# Get model prediction\n",
    "outputs = model(inputs[0].unsqueeze(0))\n",
    "_, predicted_label = torch.max(outputs, 1)\n",
    "\n",
    "# Compute attributions\n",
    "attributions = grad_cam.attribute(inputs[0].unsqueeze(0), target=predicted_label)\n",
    "\n",
    "# Convert to numpy for visualization\n",
    "attributions_np = attributions.cpu().detach().numpy()\n",
    "image_np = inputs[0].permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "# Visualize\n",
    "visualization.visualize_image_attr(attributions_np, \n",
    "                                   image_np, \n",
    "                                   method=\"heat_map\", \n",
    "                                   sign=\"absolute_value\", \n",
    "                                   title=\"Grad-CAM Heatmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "from captum.attr import LayerGradCam\n",
    "\n",
    "def generate_cam(input_model, image, layer_name=None, H=224, W=224):\n",
    "    \"\"\"\n",
    "    Generate a Grad-CAM heatmap for a given PyTorch model and image.\n",
    "    \n",
    "    Parameters:\n",
    "        input_model (torch.nn.Module): The trained PyTorch model (e.g., ResNet18).\n",
    "        image (torch.Tensor): Input image tensor of shape (C, H, W).\n",
    "        layer_name (torch.nn.Module, optional): Layer to extract CAM from (default: last conv layer).\n",
    "        H (int): Target image height.\n",
    "        W (int): Target image width.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Normalized CAM heatmap.\n",
    "    \"\"\"\n",
    "    # Ensure image is on the correct device\n",
    "    device = next(input_model.parameters()).device\n",
    "    image = image.unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "    # Forward pass to get the predicted class\n",
    "    with torch.no_grad():\n",
    "        outputs = input_model(image)\n",
    "        predicted_class = torch.argmax(outputs, dim=1).item()  # Get the class index\n",
    "\n",
    "    # Set default layer if not provided\n",
    "    if layer_name is None:\n",
    "        layer_name = input_model.layer4[-1]  # Last conv layer in ResNet\n",
    "\n",
    "    # Initialize Grad-CAM\n",
    "    grad_cam = LayerGradCam(input_model, layer_name)\n",
    "\n",
    "    # Compute attributions\n",
    "    attributions = grad_cam.attribute(image, target=predicted_class)\n",
    "\n",
    "    # Convert attributions to numpy\n",
    "    cam = attributions.squeeze().cpu().detach().numpy()\n",
    "\n",
    "    # Normalize and resize CAM to match input image size\n",
    "    cam = zoom(cam, (H / cam.shape[0], W / cam.shape[1]))\n",
    "    cam = cam / np.max(cam)  # Normalize\n",
    "\n",
    "    return cam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wh/0ws7_d4x1w39bcsy3jmhlq1w0000gn/T/ipykernel_20679/180774691.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load an image from your dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Example image (C, H, W)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Generate CAM heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Load an image from your dataset\n",
    "sample_image, _ = train_dataset[0]  # Example image (C, H, W)\n",
    "\n",
    "# Generate CAM heatmap\n",
    "heatmap = generate_cam(model, sample_image)\n",
    "\n",
    "# Visualize heatmap\n",
    "plt.imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "plt.title(\"Grad-CAM Heatmap\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "831be88b21373d988d28660f54178f22fb70e2a90418832270cb802719345912"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
